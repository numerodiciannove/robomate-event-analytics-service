# Take-home завдання: «Інгест подій та аналітика»

Мета — побудувати невеликий сервіс збору подій (events) і API для простих метрик.  

---

## Функціональні вимоги

- **Інгест подій:** `POST /events` приймає JSON-масив подій. Кожна подія має `event_id` (UUID), `occurred_at` (ISO-8601), `user_id`, `event_type` (рядок), `properties` (json-об’єкт). 
- **Ідемпотентність:** повторна відправка події з тим самим `event_id` не створює дублікат. 
- **Збереження:** вибір БД за вами (SQL/NoSQL/файлова/стовпчикова). Обґрунтуйте вибір в `ADR.md`. 
- **Запити аналітики:**
  - `GET /stats/dau?from=YYYY-MM-DD&to=YYYY-MM-DD` → кількість унікальних `user_id` по днях. 
  - `GET /stats/top-events?from&to&limit=10` → топ `event_type` за кількістю. 
  - `GET /stats/retention?start_date=YYYY-MM-DD&windows=3` → простий когортний ретеншн (тижневі або денні вікна; самі оберіть і опишіть). 
- **Імпорт історії:** CLI-скрипт `import_events <path-to-csv>` для первинного завантаження історичних даних (CSV зі стовпцями: `event_id`, `occurred_at`, `user_id`, `event_type`, `properties_json`). 

---

## Нефункціональні вимоги

- **Докер:** `docker-compose up` має підняти все потрібне. 
- **Тести:** як мінімум unit для ідемпотентності й індексації, один інтеграційний щлях «інгест → запит статистики». 
- **Спостережуваність:** структуровані логи та прості метрики (напр., кількість подій/сек, час відповіді). 
- **Продуктивність:** доведіть простий бенчмарк (опис методики + цифри), наприклад, 100k подій «залити та порахувати DAU». Окремий розділ у README — що стало вузьким місцем і як би ви це виправили. 
- **Безпека/стабільність:** валідація вхідних даних, базовий rate limit (напр., token bucket у пам’яті), акуратні коди помилок. 

---

## Опційні розширення (оберіть будь-які 2–3)

- **Черга:** асинхронний інгест через брокер (наприклад, Redis/Rabbit/NATS) з ретраями та дед-літером. 
- **Схема даних «холод/гарячий шар»:** швидкий запис + періодичний компакшн у стовпчикове сховище (DuckDB/ClickHouse/Parquet). 
- **Фільтри/групування:** `GET /stats/dau?segment=event_type:purchase` або `properties.country=UA`. 
- **Idempotency-Key для батчів:** щоб «проковтнути» дубльований upload CSV. 
- **ACL/Auth:** простий API-key або JWT. 

---

## Додаткові вимоги

- Оберіть інструмент, з яким ще не працювали (напр., DuckDB, NATS або будь-який інший), і коротко описати, що дізналися та чому саме так налаштували. 

---

## Що здати

- Посилання на репозиторій з: 
  - `README.md` (як запустити, як тестувати, що міряли, висновки). 
  - `ADR.md` (1 сторінка): альтернативи БД/веб-фреймворку/черги і чому обрали саме таку архітектуру, інструменти. Чим більше інструментарних зон розглянуто, тим краще (веб, тестування, бд і т.д.) 
  - `LEARNED.md`: що дізналися про новий обраний інструмент. 
  - Код + тести + `docker-compose.yml`. 

---
